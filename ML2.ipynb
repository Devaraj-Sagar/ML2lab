{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5tbF0PziQ2yxIR78MKbf2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devaraj-Sagar/ML2lab/blob/main/ML2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9D8VSrJeyH_",
        "outputId": "2cf5f2da-6144-4a76-fdc7-577c3424e247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialization:\n",
            "S0: [['Senior', 'Low', 'No', 'Fair', 'Unemployed', 'No']]\n",
            "G0: [['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "------------------- Instance 1 -------------------\n",
            "Instance: ['Senior', 'Low', 'No', 'Fair', 'Unemployed', 'No'], Label: Yes\n",
            "S1: [['Senior', 'Low', 'No', 'Fair', 'Unemployed', 'No']]\n",
            "G1: [['?', '?', '?', '?', '?', '?']]\n",
            "\n",
            "------------------- Instance 2 -------------------\n",
            "Instance: ['Young', 'High', 'No', 'Fair', 'Employed', 'Yes'], Label: No\n",
            "S2: [['Senior', 'Low', 'No', 'Fair', 'Unemployed', 'No']]\n",
            "G2: [['Senior', '?', '?', '?', '?', '?'], ['?', 'Low', '?', '?', '?', '?'], ['?', '?', '?', '?', 'Unemployed', '?'], ['?', '?', '?', '?', '?', 'No']]\n",
            "\n",
            "------------------- Instance 3 -------------------\n",
            "Instance: ['Young', 'Medium', 'Yes', 'Excellent', 'Employed', 'No'], Label: No\n",
            "S3: [['Senior', 'Low', 'No', 'Fair', 'Unemployed', 'No']]\n",
            "G3: [['Senior', '?', '?', '?', '?', '?'], ['?', 'Low', '?', '?', '?', '?'], ['?', '?', '?', '?', 'Unemployed', '?'], ['?', '?', 'No', '?', '?', 'No'], ['?', '?', '?', 'Fair', '?', 'No']]\n",
            "\n",
            "------------------- Instance 4 -------------------\n",
            "Instance: ['Middle', 'High', 'Yes', 'Excellent', 'Employed', 'Yes'], Label: Yes\n",
            "S4: [['?', '?', '?', '?', '?', '?']]\n",
            "G4: []\n",
            "\n",
            "Version space has collapsed. No consistent hypothesis found.\n",
            "------------------- Final Result -------------------\n",
            "Final Specific Hypothesis (S): [['?', '?', '?', '?', '?', '?']]\n",
            "Final General Hypothesis (G): []\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def is_consistent(hypothesis, instance):\n",
        "    \"\"\"Check if an instance is consistent with a hypothesis.\"\"\"\n",
        "    for i in range(len(hypothesis)):\n",
        "        if hypothesis[i] != '?' and hypothesis[i] != instance[i]:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def candidate_elimination(data):\n",
        "    \"\"\"\n",
        "    Implements the Candidate-Elimination algorithm.\n",
        "    \"\"\"\n",
        "    # Separate features (attributes) from the target\n",
        "    attributes = data.iloc[:, :-1]\n",
        "    target = data.iloc[:, -1]\n",
        "    num_attributes = len(attributes.columns)\n",
        "\n",
        "    # 1. Initialize S and G\n",
        "    # Initialize G to the most general hypothesis\n",
        "    G = [['?' for _ in range(num_attributes)]]\n",
        "\n",
        "    # Initialize S with the first positive training example\n",
        "    S = [None]\n",
        "    for i, row in data.iterrows():\n",
        "        if row.iloc[-1] == 'Yes':\n",
        "            S = [list(row.iloc[:-1])]\n",
        "            break\n",
        "\n",
        "    print(f\"Initialization:\")\n",
        "    print(f\"S0: {S}\")\n",
        "    print(f\"G0: {G}\\n\")\n",
        "\n",
        "    # 2. Iterate through the training examples\n",
        "    for i, row in data.iterrows():\n",
        "        instance = list(row.iloc[:-1])\n",
        "        label = row.iloc[-1]\n",
        "\n",
        "        print(f\"------------------- Instance {i+1} -------------------\")\n",
        "        print(f\"Instance: {instance}, Label: {label}\")\n",
        "\n",
        "        if label == 'Yes': # Positive Example\n",
        "            # Remove from G any hypothesis inconsistent with the instance\n",
        "            G = [g for g in G if is_consistent(g, instance)]\n",
        "\n",
        "            # Generalize S to be consistent with the new positive instance\n",
        "            for s_index in range(len(S)):\n",
        "                s = S[s_index]\n",
        "                if not is_consistent(s, instance):\n",
        "                    # Generalize s\n",
        "                    for attr_index in range(num_attributes):\n",
        "                        if s[attr_index] != instance[attr_index]:\n",
        "                            S[s_index][attr_index] = '?'\n",
        "\n",
        "            # Remove from S any hypothesis that is more general than another in S\n",
        "            S = [s for s in S if not any(is_more_general(s, s_other) for s_other in S if s is not s_other)]\n",
        "\n",
        "        else: # Negative Example\n",
        "            # Remove from S any hypothesis consistent with the instance (should not happen in a noise-free dataset)\n",
        "            S = [s for s in S if not is_consistent(s, instance)]\n",
        "\n",
        "            # Specialize G to exclude the negative instance\n",
        "            new_G = []\n",
        "            for g in G:\n",
        "                if not is_consistent(g, instance):\n",
        "                    new_G.append(g) # Keep it if it already excludes the instance\n",
        "                else:\n",
        "                    # Create minimal specializations\n",
        "                    for attr_index in range(num_attributes):\n",
        "                        if g[attr_index] == '?':\n",
        "                            # Get all possible values for this attribute\n",
        "                            domain = attributes.iloc[:, attr_index].unique()\n",
        "                            for value in domain:\n",
        "                                if value != instance[attr_index]:\n",
        "                                    new_g = list(g)\n",
        "                                    new_g[attr_index] = value\n",
        "                                    # Add specialization only if it's more general than some s in S\n",
        "                                    if any(is_more_general(new_g, s) for s in S):\n",
        "                                        new_G.append(new_g)\n",
        "\n",
        "            G = new_G\n",
        "            # Remove from G any hypothesis that is more specific than another in G\n",
        "            G = [g for g in G if not any(is_more_general(g_other, g) for g_other in G if g is not g_other)]\n",
        "\n",
        "\n",
        "        print(f\"S{i+1}: {S}\")\n",
        "        print(f\"G{i+1}: {G}\\n\")\n",
        "\n",
        "        # If either boundary becomes empty, the version space has collapsed\n",
        "        if not S or not G:\n",
        "            print(\"Version space has collapsed. No consistent hypothesis found.\")\n",
        "            break\n",
        "\n",
        "    return S, G\n",
        "\n",
        "def is_more_general(h1, h2):\n",
        "    \"\"\"Check if hypothesis h1 is more general than or equal to h2.\"\"\"\n",
        "    more_general_parts = []\n",
        "    for x, y in zip(h1, h2):\n",
        "        mg = x == '?' or (x != '?' and x == y)\n",
        "        more_general_parts.append(mg)\n",
        "    return all(more_general_parts)\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "# Create the dataset from the image\n",
        "data = {\n",
        "    'Age': ['Senior', 'Young', 'Young', 'Middle', 'Young', 'Senior'],\n",
        "    'Income': ['Low', 'High', 'Medium', 'High', 'Low', 'Medium'],\n",
        "    'Student': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No'],\n",
        "    'Credit_Rating': ['Fair', 'Fair', 'Excellent', 'Excellent', 'Fair', 'Fair'],\n",
        "    'Employment': ['Unmployed', 'Employed', 'Employed', 'Employed', 'Unemployed', 'Employed'], # Correction based on image\n",
        "    'Collateral': ['No', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
        "    'Loan_Approved': ['Yes', 'No', 'No', 'Yes', 'Yes', 'Yes']\n",
        "}\n",
        "\n",
        "# The first instance has 'Unemployed'. Let's correct the whole column based on the image.\n",
        "data['Employment'] = ['Unemployed', 'Employed', 'Employed', 'Employed', 'Unemployed', 'Employed']\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Run the algorithm\n",
        "final_S, final_G = candidate_elimination(df)\n",
        "\n",
        "print(\"------------------- Final Result -------------------\")\n",
        "print(\"Final Specific Hypothesis (S):\", final_S)\n",
        "print(\"Final General Hypothesis (G):\", final_G)"
      ]
    }
  ]
}